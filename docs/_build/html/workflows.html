

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Processing pipeline details &mdash; aslprep version documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
        <script type="text/javascript" src="https://cdn.rawgit.com/chrisfilo/zenodo.js/v0.1/zenodo.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/theme_overrides.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Susceptibility Distortion Correction (SDC)" href="sdc.html" />
    <link rel="prev" title="Running ASLPrep via Singularity containers" href="singularity.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> aslprep
          

          
          </a>

          
            
            
              <div class="version">
                version
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="docker.html">Running <em>aslprep</em> via Docker containers</a></li>
<li class="toctree-l1"><a class="reference internal" href="singularity.html">Running <em>ASLPrep</em> via Singularity containers</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Processing pipeline details</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#preprocessing-of-structural-mri">Preprocessing of structural MRI</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#brain-extraction-brain-tissue-segmentation-and-spatial-normalization">Brain extraction, brain tissue segmentation and spatial normalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cost-function-masking-during-spatial-normalization">Cost function masking during spatial normalization</a></li>
<li class="toctree-l3"><a class="reference internal" href="#longitudinal-processing">Longitudinal processing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#surface-preprocessing">Surface preprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="#refinement-of-the-brain-mask">Refinement of the brain mask</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#aslprep-preprocessing">ASLPrep preprocessing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#asl-reference-image-estimation">ASL reference image estimation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#head-motion-estimation">Head-motion estimation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#slice-time-correction">Slice time correction</a></li>
<li class="toctree-l3"><a class="reference internal" href="#susceptibility-distortion-correction-sdc">Susceptibility Distortion Correction (SDC)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pre-processed-asl-in-native-space">Pre-processed ASL in native space</a></li>
<li class="toctree-l3"><a class="reference internal" href="#cbf-computation-in-native-space">CBF Computation in native space</a></li>
<li class="toctree-l3"><a class="reference internal" href="#asl-and-cbf-to-t1w-registration">ASL and CBF to T1w registration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#resampling-asl-and-cbf-runs-onto-standard-spaces">Resampling ASL  and CBF runs onto standard spaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="#asl-sampled-to-freesurfer-surfaces">ASL sampled to FreeSurfer surfaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="#hcp-grayordinates">HCP Grayordinates</a></li>
<li class="toctree-l3"><a class="reference internal" href="#confounds-estimation">Confounds estimation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#t2-driven-coregistration">T2* Driven Coregistration</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="sdc.html">Susceptibility Distortion Correction (SDC)</a></li>
<li class="toctree-l1"><a class="reference internal" href="outputs.html">Outputs of <em>ASLPrep</em></a></li>
<li class="toctree-l1"><a class="reference internal" href="spaces.html">Defining standard and nonstandard spaces where data will be resampled</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ, Tips, and Tricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="contributors.html">Contributing to ASLPREP</a></li>
<li class="toctree-l1"><a class="reference internal" href="citing.html">Citing <em>ASLPrep</em></a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">Developers - API</a></li>
<li class="toctree-l1"><a class="reference internal" href="changes.html">What’s new</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">aslprep</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Processing pipeline details</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/workflows.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="processing-pipeline-details">
<h1>Processing pipeline details<a class="headerlink" href="#processing-pipeline-details" title="Permalink to this headline">¶</a></h1>
<p><em>ASLPrep</em> adapts its pipeline depending on what data and metadata are
available and are used as the input.
For example, slice timing correction will be
performed only if the <code class="docutils literal notranslate"><span class="pre">SliceTiming</span></code> metadata field is found for the input
dataset.</p>
<p>A (very) high-level view of the simplest pipeline (for a single-band dataset with only
one task, single-run, with no slice-timing information nor fieldmap acquisitions)
is presented below:</p>
<p>(<a class="reference external" href=".//workflows-1.py">Source code</a>)</p>
<div class="section" id="preprocessing-of-structural-mri">
<h2>Preprocessing of structural MRI<a class="headerlink" href="#preprocessing-of-structural-mri" title="Permalink to this headline">¶</a></h2>
<p>The anatomical sub-workflow begins by constructing an average image by
conforming all found T1w images to RAS orientation and
a common voxel size, and, in the case of multiple images, averages them into a
single reference template (see <a class="reference internal" href="#longitudinal-processing">Longitudinal processing</a>).</p>
<p>(<a class="reference external" href=".//workflows-2.py">Source code</a>)</p>
<p>See also <em>sMRIPrep</em>’s
<code class="xref py py-func docutils literal notranslate"><span class="pre">init_anat_preproc_wf()</span></code>.</p>
<div class="section" id="brain-extraction-brain-tissue-segmentation-and-spatial-normalization">
<span id="t1preproc-steps"></span><h3>Brain extraction, brain tissue segmentation and spatial normalization<a class="headerlink" href="#brain-extraction-brain-tissue-segmentation-and-spatial-normalization" title="Permalink to this headline">¶</a></h3>
<p>Then, the T1w reference is skull-stripped using a Nipype implementation of
the <code class="docutils literal notranslate"><span class="pre">antsBrainExtraction.sh</span></code> tool (ANTs), which is an atlas-based
brain extraction workflow:</p>
<p>(<a class="reference external" href=".//workflows-3.py">Source code</a>)</p>
<p>An example of brain extraction is shown below:</p>
<div class="figure align-default" id="id3">
<img alt="_images/brainextraction_t1.svg" src="_images/brainextraction_t1.svg" /><p class="caption"><span class="caption-text">Brain extraction</span><a class="headerlink" href="#id3" title="Permalink to this image">¶</a></p>
</div>
<p>Once the brain mask is computed, FSL <code class="docutils literal notranslate"><span class="pre">fast</span></code> is utilized for brain tissue segmentation.</p>
<div class="figure align-default" id="id4">
<img alt="_images/segmentation.svg" src="_images/segmentation.svg" /><p class="caption"><span class="caption-text">Brain tissue segmentation.</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
<p>Finally, spatial normalization to standard spaces is performed using ANTs’ <code class="docutils literal notranslate"><span class="pre">antsRegistration</span></code>
in a multiscale, mutual-information based, nonlinear registration scheme.
See <a class="reference internal" href="spaces.html#output-spaces"><span class="std std-ref">Defining standard and nonstandard spaces where data will be resampled</span></a> for information about how standard and nonstandard spaces can
be set to resample the preprocessed data onto the final output spaces.</p>
<div class="figure align-default" id="id5">
<img alt="_images/T1MNINormalization.svg" src="_images/T1MNINormalization.svg" /><p class="caption"><span class="caption-text">Animation showing spatial normalization of T1w onto the <code class="docutils literal notranslate"><span class="pre">MNI152NLin2009cAsym</span></code> template.</span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="cost-function-masking-during-spatial-normalization">
<h3>Cost function masking during spatial normalization<a class="headerlink" href="#cost-function-masking-during-spatial-normalization" title="Permalink to this headline">¶</a></h3>
<p>When processing images from patients with focal brain lesions (e.g., stroke, tumor
resection), it is possible to provide a lesion mask to be used during spatial
normalization to standard space <span id="id1">[Brett2001]</span>.
ANTs will use this mask to minimize warping of healthy tissue into damaged
areas (or vice-versa).
Lesion masks should be binary NIfTI images (damaged areas = 1, everywhere else = 0)
in the same space and resolution as the T1 image, and follow the naming convention specified in
<a class="reference external" href="https://docs.google.com/document/d/1Wwc4A6Mow4ZPPszDIWfCUCRNstn7d_zzaWPcfcHmgI4/edit#heading=h.9146wuepclkt">BIDS Extension Proposal 3: Common Derivatives</a>
(e.g., <code class="docutils literal notranslate"><span class="pre">sub-001_T1w_label-lesion_roi.nii.gz</span></code>).
This file should be placed in the <code class="docutils literal notranslate"><span class="pre">sub-*/anat</span></code> directory of the BIDS dataset
to be run through <em>fMRIPrep</em>.
Because lesion masks are not currently part of the BIDS specification, it is also necessary to
include a <code class="docutils literal notranslate"><span class="pre">.bidsignore</span></code> file in the root of your dataset directory. This will prevent
<a class="reference external" href="https://github.com/bids-standard/bids-validator#bidsignore">bids-validator</a> from complaining
that your dataset is not valid BIDS, which prevents <em>fMRIPrep</em> from running.
Your <code class="docutils literal notranslate"><span class="pre">.bidsignore</span></code> file should include the following line:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">*</span><span class="n">lesion_roi</span><span class="o">.</span><span class="n">nii</span><span class="o">.</span><span class="n">gz</span>
</pre></div>
</div>
</div>
<div class="section" id="longitudinal-processing">
<h3>Longitudinal processing<a class="headerlink" href="#longitudinal-processing" title="Permalink to this headline">¶</a></h3>
<p>In the case of multiple T1w images (across sessions and/or runs), T1w images are
merged into a single template image using FreeSurfer’s <a class="reference external" href="https://surfer.nmr.mgh.harvard.edu/fswiki/mri_robust_template">mri_robust_template</a>.
This template may be <em>unbiased</em>, or equidistant from all source images, or
aligned to the first image (determined lexicographically by session label).
For two images, the additional cost of estimating an unbiased template is
trivial and is the default behavior, but, for greater than two images, the cost
can be a slowdown of an order of magnitude.
Therefore, in the case of three or more images, <em>ASLPrep</em> constructs
templates aligned to the first image, unless passed the <code class="docutils literal notranslate"><span class="pre">--longitudinal</span></code>
flag, which forces the estimation of an unbiased template.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The preprocessed T1w image defines the <code class="docutils literal notranslate"><span class="pre">T1w</span></code> space.
In the case of multiple T1w images, this space may not be precisely aligned
with any of the original images.
Reconstructed surfaces and functional datasets will be registered to the
<code class="docutils literal notranslate"><span class="pre">T1w</span></code> space, and not to the input images.</p>
</div>
</div>
<div class="section" id="surface-preprocessing">
<span id="workflows-surface"></span><h3>Surface preprocessing<a class="headerlink" href="#surface-preprocessing" title="Permalink to this headline">¶</a></h3>
<p><em>ASLPrep</em> uses <a class="reference external" href="https://surfer.nmr.mgh.harvard.edu/">FreeSurfer</a> to reconstruct surfaces from T1w/T2w
structural images.
If enabled, several steps in the <em>ASLPrep</em> pipeline are added or replaced.
All surface preprocessing may be disabled with the <code class="docutils literal notranslate"><span class="pre">--fs-no-reconall</span></code> flag.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Surface processing will be skipped if the outputs already exist.</p>
<p>In order to bypass reconstruction in <em>ASLPrep</em>, place existing reconstructed
subjects in <code class="docutils literal notranslate"><span class="pre">&lt;output</span> <span class="pre">dir&gt;/freesurfer</span></code> prior to the run, or specify an external
subjects directory with the <code class="docutils literal notranslate"><span class="pre">--fs-subjects-dir</span></code> flag.
<em>ASLPrep</em> will perform any missing <code class="docutils literal notranslate"><span class="pre">recon-all</span></code> steps, but will not perform
any steps whose outputs already exist.</p>
</div>
<p>If FreeSurfer reconstruction is performed, the reconstructed subject is placed in
<code class="docutils literal notranslate"><span class="pre">&lt;output</span> <span class="pre">dir&gt;/freesurfer/sub-&lt;subject_label&gt;/</span></code> (see <a class="reference internal" href="outputs.html#fsderivs"><span class="std std-ref">FreeSurfer derivatives</span></a>).</p>
<p>Surface reconstruction is performed in three phases.
The first phase initializes the subject with T1w and T2w (if available)
structural images and performs basic reconstruction (<code class="docutils literal notranslate"><span class="pre">autorecon1</span></code>) with the
exception of skull-stripping.
Skull-stripping is skipped since the brain mask <a class="reference internal" href="#t1preproc-steps"><span class="std std-ref">calculated previously</span></a> is injected into the appropriate location for FreeSurfer.
For example, a subject with only one session with T1w and T2w images
would be processed by the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ recon-all -sd &lt;output dir&gt;/freesurfer -subjid sub-&lt;subject_label&gt; \
    -i &lt;bids-root&gt;/sub-&lt;subject_label&gt;/anat/sub-&lt;subject_label&gt;_T1w.nii.gz \
    -T2 &lt;bids-root&gt;/sub-&lt;subject_label&gt;/anat/sub-&lt;subject_label&gt;_T2w.nii.gz \
    -autorecon1 \
    -noskullstrip
</pre></div>
</div>
<p>The second phase imports the brainmask calculated in the
<a class="reference internal" href="#preprocessing-of-structural-mri">Preprocessing of structural MRI</a> sub-workflow.
The final phase resumes reconstruction, using the T2w image to assist
in finding the pial surface, if available.
See <code class="xref py py-func docutils literal notranslate"><span class="pre">init_autorecon_resume_wf()</span></code> for
details.</p>
<p>Reconstructed white and pial surfaces are included in the report.</p>
<div class="figure align-default" id="id6">
<img alt="_images/reconall.svg" src="_images/reconall.svg" /><p class="caption"><span class="caption-text">Surface reconstruction (FreeSurfer)</span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</div>
<p>If T1w voxel sizes are less than 1mm in all dimensions (rounding to nearest
.1mm), <a class="reference external" href="https://surfer.nmr.mgh.harvard.edu/fswiki/SubmillimeterRecon">submillimeter reconstruction</a> is used, unless disabled with
<code class="docutils literal notranslate"><span class="pre">--no-submm-recon</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">lh.midthickness</span></code> and <code class="docutils literal notranslate"><span class="pre">rh.midthickness</span></code> surfaces are created in the subject
<code class="docutils literal notranslate"><span class="pre">surf/</span></code> directory, corresponding to the surface half-way between the gray/white
boundary and the pial surface.
The <code class="docutils literal notranslate"><span class="pre">smoothwm</span></code>, <code class="docutils literal notranslate"><span class="pre">midthickness</span></code>, <code class="docutils literal notranslate"><span class="pre">pial</span></code> and <code class="docutils literal notranslate"><span class="pre">inflated</span></code> surfaces are also
converted to <a class="reference external" href="https://www.nitrc.org/projects/gifti/">GIFTI</a> format and adjusted to be compatible with multiple software
packages, including FreeSurfer and the <a class="reference external" href="https://www.humanconnectome.org/software/connectome-workbench.html">Connectome Workbench</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>GIFTI surface outputs are aligned to the FreeSurfer T1.mgz image, which
may differ from the T1w space in some cases, to maintain compatibility
with the FreeSurfer directory.
Any measures sampled to the surface take into account any difference in
these images.</p>
</div>
<p>(<a class="reference external" href=".//workflows-4.py">Source code</a>)</p>
<p>See also <em>sMRIPrep</em>’s
<code class="xref py py-func docutils literal notranslate"><span class="pre">init_surface_recon_wf()</span></code></p>
</div>
<div class="section" id="refinement-of-the-brain-mask">
<h3>Refinement of the brain mask<a class="headerlink" href="#refinement-of-the-brain-mask" title="Permalink to this headline">¶</a></h3>
<p>Typically, the original brain mask calculated with <code class="docutils literal notranslate"><span class="pre">antsBrainExtraction.sh</span></code>
will contain some innaccuracies including small amounts of MR signal from
outside the brain.
Based on the tissue segmentation of FreeSurfer (located in <code class="docutils literal notranslate"><span class="pre">mri/aseg.mgz</span></code>)
and only when the <a class="reference internal" href="#workflows-surface"><span class="std std-ref">Surface Processing</span></a> step has been
executed, <em>ASLPrep</em> replaces the brain mask with a refined one that derives
from the <code class="docutils literal notranslate"><span class="pre">aseg.mgz</span></code> file as described in
<code class="xref py py-func docutils literal notranslate"><span class="pre">grow_mask()</span></code>.</p>
</div>
</div>
<div class="section" id="aslprep-preprocessing">
<h2>ASLPrep preprocessing<a class="headerlink" href="#aslprep-preprocessing" title="Permalink to this headline">¶</a></h2>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">init_func_preproc_wf()</span></code></p>
<p>(<a class="reference external" href=".//workflows-5.py">Source code</a>)</p>
<p>Preprocessing of <abbr title="Arterial Spin Labelling">ASL</abbr> files is
split into multiple sub-workflows described below.</p>
<div class="section" id="asl-reference-image-estimation">
<span id="asl-ref"></span><h3>ASL reference image estimation<a class="headerlink" href="#asl-reference-image-estimation" title="Permalink to this headline">¶</a></h3>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">init_bold_reference_wf()</span></code></p>
<p>(<a class="reference external" href=".//workflows-6.py">Source code</a>)</p>
<p>This workflow estimates a reference image for a
<abbr title="Arterial Spin Labelling">ASL</abbr> series.
When T1-saturation effects (“dummy scans” or non-steady state volumes) are
detected, they are averaged and used as reference due to their
superior tissue contrast.
Otherwise, a median of motion corrected subset of volumes is used.</p>
<p>The reference image is then used to calculate a brain mask for the
<abbr title="Arterial Spin Labelling">ASL</abbr> signal using <em>NiWorkflows</em>’
<code class="xref py py-func docutils literal notranslate"><span class="pre">init_enhance_and_skullstrip_bold_wf()</span></code>.
Further, the reference is fed to the <a class="reference internal" href="#asl-hmc"><span class="std std-ref">head-motion estimation
workflow</span></a> and the <a class="reference internal" href="#asl-reg"><span class="std std-ref">registration workflow to map
BOLD series into the T1w image of the same subject</span></a>.</p>
<div class="figure align-default" id="id7">
<img alt="_images/brainextraction.svg" src="_images/brainextraction.svg" /><p class="caption"><span class="caption-text">Calculation of a brain mask from the BOLD series.</span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="head-motion-estimation">
<span id="asl-hmc"></span><h3>Head-motion estimation<a class="headerlink" href="#head-motion-estimation" title="Permalink to this headline">¶</a></h3>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">init_bold_hmc_wf()</span></code></p>
<p>(<a class="reference external" href=".//workflows-7.py">Source code</a>)</p>
<p>Using the previously <a class="reference internal" href="#asl-ref"><span class="std std-ref">estimated reference scan</span></a>,
FSL <code class="docutils literal notranslate"><span class="pre">mcflirt</span></code> is used to estimate head-motion.
As a result, one rigid-body transform with respect to
the reference image is written for each <abbr title="Arterial Spin Labelling">ASL</abbr>
time-step.
Additionally, a list of 6-parameters (three rotations,
three translations) per time-step is written and fed to the
<a class="reference internal" href="#asl-confounds"><span class="std std-ref">confounds workflow</span></a>.
For a more accurate estimation of head-motion, we calculate its parameters
before any time-domain filtering (i.e., <a class="reference internal" href="#asl-stc"><span class="std std-ref">slice-timing correction</span></a>),
as recommended in <span id="id2">[Power2017]</span>.</p>
</div>
<div class="section" id="slice-time-correction">
<span id="asl-stc"></span><h3>Slice time correction<a class="headerlink" href="#slice-time-correction" title="Permalink to this headline">¶</a></h3>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">init_bold_stc_wf()</span></code></p>
<p>(<a class="reference external" href=".//workflows-8.py">Source code</a>)</p>
<p>If the <code class="docutils literal notranslate"><span class="pre">SliceTiming</span></code> field is available within the input dataset metadata,
this workflow performs slice time correction prior to other signal resampling
processes.
Slice time correction is performed using AFNI <code class="docutils literal notranslate"><span class="pre">3dTShift</span></code>.
All slices are realigned in time to the middle of each TR.</p>
<p>Slice time correction can be disabled with the <code class="docutils literal notranslate"><span class="pre">--ignore</span> <span class="pre">slicetiming</span></code>
command line argument.
If a <abbr title="Arterial Spin Labelling">ASL</abbr> series has fewer than
5 usable (steady-state) volumes, slice time correction will be disabled
for that run.</p>
</div>
<div class="section" id="susceptibility-distortion-correction-sdc">
<h3>Susceptibility Distortion Correction (SDC)<a class="headerlink" href="#susceptibility-distortion-correction-sdc" title="Permalink to this headline">¶</a></h3>
<p>One of the major problems that affects <abbr title="echo planar imaging">EPI</abbr> data
is the spatial distortion caused by the inhomogeneity of the field inside
the scanner.
Please refer to <a class="reference internal" href="sdc.html#sdc"><span class="std std-ref">Susceptibility Distortion Correction (SDC)</span></a> for details on the
available workflows.</p>
<div class="figure align-default" id="id8">
<img alt="_images/unwarping.svg" src="_images/unwarping.svg" /><p class="caption"><span class="caption-text">Applying susceptibility-derived distortion correction, based on
fieldmap estimation.</span><a class="headerlink" href="#id8" title="Permalink to this image">¶</a></p>
</div>
<p>See also <em>SDCFlows</em>’ <a class="reference external" href="https://www.nipreps.org/sdcflows/api/sdcflows.workflows.base.html#sdcflows.workflows.base.init_sdc_estimate_wf" title="(in sdcflows v1.2.3)"><code class="xref py py-func docutils literal notranslate"><span class="pre">init_sdc_estimate_wf()</span></code></a></p>
</div>
<div class="section" id="pre-processed-asl-in-native-space">
<span id="asl-preproc"></span><h3>Pre-processed ASL in native space<a class="headerlink" href="#pre-processed-asl-in-native-space" title="Permalink to this headline">¶</a></h3>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">init_bold_preproc_trans_wf()</span></code></p>
<p>(<a class="reference external" href=".//workflows-9.py">Source code</a>)</p>
<p>A new <em>preproc</em> <abbr title="Arterial Spin Labelling">ASL</abbr> series is generated
from the slice-timing corrected or the original data (if
<abbr title="slice-timing correction">STC</abbr> was not applied) in the
original space.
All volumes in the <abbr title="Arterial Spin Labelling">ASL</abbr> series are
resampled in their native space by concatenating the mappings found in previous
correction workflows (<abbr title="head-motion correction">HMC</abbr> and
<abbr title="susceptibility-derived distortion correction">SDC</abbr> if excecuted)
for a one-shot interpolation process.
Interpolation uses a Lanczos kernel.</p>
</div>
<div class="section" id="cbf-computation-in-native-space">
<span id="cbf-preproc"></span><h3>CBF Computation in native space<a class="headerlink" href="#cbf-computation-in-native-space" title="Permalink to this headline">¶</a></h3>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">init_cbf_compt_wf()</span></code></p>
<p>(<a class="reference external" href=".//workflows-10.py">Source code</a>)</p>
<p>ALl the CBF derivates are computed from preprocessed <a class="reference internal" href="#asl-preproc"><span class="std std-ref">ASL</span></a>.
This inlude CBF computation by basic model and <abbr title="Bayesian Inference for Arterial Spin Labeling ">BASIL</abbr>.
The BASIL includes spatial regularization and partial volume correction.
The computed CBF are further denoised by <abbr title="Structural Correlation based Outlier Rejection">SCORE</abbr>
and <abbr title="Structural Correlation withRobUst Bayesian">SCRUB</abbr></p>
</div>
<div class="section" id="asl-and-cbf-to-t1w-registration">
<span id="asl-reg"></span><h3>ASL and CBF to T1w registration<a class="headerlink" href="#asl-and-cbf-to-t1w-registration" title="Permalink to this headline">¶</a></h3>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">init_bold_reg_wf()</span></code></p>
<p>(<a class="reference external" href=".//workflows-11.py">Source code</a>)</p>
<p>The alignment between the reference <abbr title="arterial spin labelling">ASL</abbr> image
of each run and the reconstructed subject using the gray/white matter boundary
(FreeSurfer’s <code class="docutils literal notranslate"><span class="pre">?h.white</span></code> surfaces) is calculated by the <code class="docutils literal notranslate"><span class="pre">bbregister</span></code> routine.</p>
<div class="figure align-default" id="id9">
<img alt="_images/EPIT1Normalization.svg" src="_images/EPIT1Normalization.svg" /><p class="caption"><span class="caption-text">Animation showing <abbr title="arterial spin labelling">ASL</abbr> to T1w registration (FreeSurfer <code class="docutils literal notranslate"><span class="pre">bbregister</span></code>)</span><a class="headerlink" href="#id9" title="Permalink to this image">¶</a></p>
</div>
<p>If FreeSurfer processing is disabled, FSL <code class="docutils literal notranslate"><span class="pre">flirt</span></code> is run with the
<abbr title="boundary-based registration">BBR</abbr> cost function, using the
<code class="docutils literal notranslate"><span class="pre">fast</span></code> segmentation to establish the gray/white matter boundary.
After <abbr title="boundary-based registration">BBR</abbr> is run, the resulting affine transform will be compared to the initial transform found by FLIRT.
Excessive deviation will result in rejecting the BBR refinement and accepting the original, affine registration.
The computed <a class="reference internal" href="#cbf-preproc"><span class="std std-ref">CBF</span></a>  are regsitered to T1w using the transformation from ASL-T1w registration.</p>
</div>
<div class="section" id="resampling-asl-and-cbf-runs-onto-standard-spaces">
<h3>Resampling ASL  and CBF runs onto standard spaces<a class="headerlink" href="#resampling-asl-and-cbf-runs-onto-standard-spaces" title="Permalink to this headline">¶</a></h3>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">init_bold_std_trans_wf()</span></code></p>
<p>(<a class="reference external" href=".//workflows-12.py">Source code</a>)</p>
<p>This sub-workflow concatenates the transforms calculated upstream (see
<a class="reference internal" href="#head-motion-estimation">Head-motion estimation</a>, <a class="reference internal" href="#susceptibility-distortion-correction-sdc">Susceptibility Distortion Correction (SDC)</a> –if
fieldmaps are available–, <a href="#id10"><span class="problematic" id="id11">`EPI to T1w registration`_</span></a>, and an anatomical-to-standard
transform from <a class="reference internal" href="#preprocessing-of-structural-mri">Preprocessing of structural MRI</a>) to map the
<abbr title="echo-planar imaging">EPI</abbr>
image to the standard spaces given by the <code class="docutils literal notranslate"><span class="pre">--output-spaces</span></code> argument
(see <a class="reference internal" href="spaces.html#output-spaces"><span class="std std-ref">Defining standard and nonstandard spaces where data will be resampled</span></a>).
It also maps the T1w-based mask to each of those standard spaces.</p>
<p>Transforms are concatenated and applied all at once, with one interpolation (Lanczos)
step, so as little information is lost as possible.</p>
<p>The output space grid can be specified using modifiers to the <code class="docutils literal notranslate"><span class="pre">--output-spaces</span></code>
argument.</p>
</div>
<div class="section" id="asl-sampled-to-freesurfer-surfaces">
<h3>ASL sampled to FreeSurfer surfaces<a class="headerlink" href="#asl-sampled-to-freesurfer-surfaces" title="Permalink to this headline">¶</a></h3>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">init_bold_surf_wf()</span></code></p>
<p>(<a class="reference external" href=".//workflows-13.py">Source code</a>)</p>
<p>If FreeSurfer processing is enabled, the motion-corrected functional series
(after single shot resampling to T1w space) is sampled to the
surface by averaging across the cortical ribbon.
Specifically, at each vertex, the segment normal to the white-matter surface, extending to the pial
surface, is sampled at 6 intervals and averaged.</p>
<p>Surfaces are generated for the “subject native” surface, as well as transformed to the
<code class="docutils literal notranslate"><span class="pre">fsaverage</span></code> template space.
All surface outputs are in GIFTI format.</p>
</div>
<div class="section" id="hcp-grayordinates">
<h3>HCP Grayordinates<a class="headerlink" href="#hcp-grayordinates" title="Permalink to this headline">¶</a></h3>
<p>If CIFTI output is enabled, the motion-corrected functional timeseries (in T1w space) is first
sampled to the high resolution 164k vertex (per hemisphere) <code class="docutils literal notranslate"><span class="pre">fsaverage</span></code>. Following that,
the resampled timeseries is sampled to <cite>HCP Pipelines_</cite>’s <code class="docutils literal notranslate"><span class="pre">fsLR</span></code> mesh (with the left and
right hemisphere aligned) using <a class="reference external" href="https://www.humanconnectome.org/software/connectome-workbench.html">Connectome Workbench</a>’s <code class="docutils literal notranslate"><span class="pre">-metric-resample</span></code> to generate a
surface timeseries for each hemisphere. These surfaces are then combined with corresponding
volumetric timeseries to create a CIFTI2 file.</p>
</div>
<div class="section" id="confounds-estimation">
<span id="asl-confounds"></span><h3>Confounds estimation<a class="headerlink" href="#confounds-estimation" title="Permalink to this headline">¶</a></h3>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">init_bold_confs_wf()</span></code></p>
<p>(<a class="reference external" href=".//workflows-14.py">Source code</a>)</p>
<p>Given a motion-corrected ASL, a brain mask, <code class="docutils literal notranslate"><span class="pre">mcflirt</span></code> movement parameters and a
segmentation, the <cite>discover_wf</cite> sub-workflow calculates potential
confounds per volume.</p>
<p>Calculated confounds include Frame-wise Displacement, 6 motion parameters, DVARS.</p>
</div>
<div class="section" id="t2-driven-coregistration">
<span id="asl-t2s"></span><h3>T2* Driven Coregistration<a class="headerlink" href="#t2-driven-coregistration" title="Permalink to this headline">¶</a></h3>
<p><code class="xref py py-func docutils literal notranslate"><span class="pre">init_bold_t2s_wf()</span></code></p>
<p>If multi-echo <abbr title="arterial spin labellin">ASL</abbr> data is supplied,
this workflow uses the <a class="reference external" href="https://github.com/me-ica/tedana">tedana</a> <a class="reference external" href="https://tedana.readthedocs.io/en/latest/generated/tedana.workflows.t2smap_workflow.html#tedana.workflows.t2smap_workflow#noqa">T2* workflow</a> to generate an adaptive T2* map
and optimally weighted combination of all supplied single echo time series.
This optimaly combined time series is then carried forward for all subsequent
preprocessing steps.
Optionally, if the <code class="docutils literal notranslate"><span class="pre">--t2s-coreg</span></code> flag is supplied, the T2* map is then used
in place of the <a class="reference internal" href="#asl-ref"><span class="std std-ref">ASL reference image</span></a> to
<a class="reference internal" href="#asl-reg"><span class="std std-ref">register the ASL series to the T1w image</span></a> of the same subject.</p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="sdc.html" class="btn btn-neutral float-right" title="Susceptibility Distortion Correction (SDC)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="singularity.html" class="btn btn-neutral float-left" title="Running ASLPrep via Singularity containers" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020-2020, The ASLPREP developers

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>