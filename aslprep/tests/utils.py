"""Utility functions for tests."""

import os
import tarfile
from contextlib import contextmanager
from glob import glob
from gzip import GzipFile
from io import BytesIO

import nibabel as nb
import numpy as np
import requests
from bids.layout import BIDSLayout
from nipype import logging

from aslprep import config

LOGGER = logging.getLogger('nipype.utils')


def download_test_data(dset, data_dir=None):
    """Download test data."""
    URLS = {
        'anatomical': (
            'https://upenn.box.com/shared/static/310po9aj05iczko0qvlp21gk19upj82d.tar.gz'
        ),
        'examples_pasl_multipld': (
            'https://upenn.box.com/shared/static/njb5tqs2n53775qumtwc1wyxo5362sp7.tar.gz'
        ),
        'examples_pcasl_multipld': (
            'https://upenn.box.com/shared/static/pm0ysafvg69jimk1bcm3ewtljiwzk899.tar.gz'
        ),
        'examples_pcasl_singlepld': (
            'https://upenn.box.com/shared/static/il6cfea6f0wjnmjjvcpg6baw3e7yrwa3.tar.gz'
        ),
        'qtab': 'https://upenn.box.com/shared/static/ap5ftlc3logivmj03fabuahv4etqk7jf.tar.gz',
        'test_001': 'https://upenn.box.com/shared/static/cudw5yyh3j6jwymmlzdw2nwc6knmxdu9.tar.gz',
        'test_002': 'https://upenn.box.com/shared/static/wpuvn06zl4v5nwd9o8tysyfs3kg4a2p0.tar.gz',
        'test_003': 'https://upenn.box.com/shared/static/1c64kn7btb5dodksnn06wer2kfk00px5.tar.gz',
    }
    if dset == '*':
        for k in URLS:
            download_test_data(k, data_dir=data_dir)

        return

    if dset not in URLS:
        raise ValueError(f'dset ({dset}) must be one of: {", ".join(URLS.keys())}')

    if not data_dir:
        data_dir = os.path.join(os.path.dirname(get_test_data_path()), 'test_data')

    out_dir = os.path.join(data_dir, dset)

    if os.path.isdir(out_dir):
        config.loggers.utils.info(
            f'Dataset {dset} already exists. '
            'If you need to re-download the data, please delete the folder.'
        )
        return out_dir
    else:
        config.loggers.utils.info(f'Downloading {dset} to {out_dir}')

    os.makedirs(out_dir, exist_ok=True)
    with requests.get(URLS[dset], stream=True, timeout=10) as req:
        with tarfile.open(fileobj=GzipFile(fileobj=BytesIO(req.content))) as t:
            t.extractall(out_dir)  # noqa: S202

    return out_dir


def get_test_data_path():
    """Return the path to test datasets, terminated with separator.

    Test-related data are kept in tests folder in "data".
    Based on function by Yaroslav Halchenko used in Neurosynth Python package.
    """
    return os.path.abspath(os.path.join(os.path.dirname(__file__), 'data') + os.path.sep)


def check_generated_files(aslprep_dir, output_list_file):
    """Compare files generated by aslprep with a list of expected files."""
    found_files = sorted(glob(os.path.join(aslprep_dir, '**/*'), recursive=True))
    found_files = [os.path.relpath(f, aslprep_dir) for f in found_files]

    # Ignore figures
    found_files = [f for f in found_files if 'figures' not in f]

    # Ignore logs
    found_files = [f for f in found_files if 'log' not in f.split(os.path.sep)]

    with open(output_list_file) as fobj:
        expected_files = fobj.readlines()
        expected_files = [f.rstrip() for f in expected_files]

    if sorted(set(found_files)) != sorted(set(expected_files)):
        expected_not_found = sorted(set(expected_files) - set(found_files))
        found_not_expected = sorted(set(found_files) - set(expected_files))

        msg = ''
        if expected_not_found:
            msg += '\nExpected but not found:\n\t'
            msg += '\n\t'.join(expected_not_found)

        if found_not_expected:
            msg += '\nFound but not expected:\n\t'
            msg += '\n\t'.join(found_not_expected)
        raise ValueError(msg)


def check_affines(data_dir, out_dir, input_type):
    """Confirm affines don't change across XCP runs."""
    fmri_layout = BIDSLayout(str(data_dir), validate=False, derivatives=False)
    xcp_layout = BIDSLayout(str(out_dir), validate=False, derivatives=False)
    if input_type == 'cifti':  # Get the .dtseries.nii
        denoised_files = xcp_layout.get(
            invalid_filters='allow',
            datatype='func',
            run=1,
            extension='.dtseries.nii',
        )
        space = denoised_files[0].get_entities()['space']
        bold_files = fmri_layout.get(
            invalid_filters='allow',
            datatype='func',
            run=1,
            space=space,
            extension='.dtseries.nii',
        )

    elif input_type == 'nifti':  # Get the .nii.gz
        # Problem: it's collecting native-space data
        denoised_files = xcp_layout.get(
            datatype='func',
            run=1,
            suffix='bold',
            extension='.nii.gz',
        )
        space = denoised_files[0].get_entities()['space']
        bold_files = fmri_layout.get(
            invalid_filters='allow',
            datatype='func',
            run=1,
            space=space,
            suffix='bold',
            extension='.nii.gz',
        )

    else:  # Nibabies
        denoised_files = xcp_layout.get(
            datatype='func',
            space='MNIInfant',
            suffix='bold',
            extension='.nii.gz',
        )
        bold_files = fmri_layout.get(
            invalid_filters='allow',
            datatype='func',
            space='MNIInfant',
            suffix='bold',
            extension='.nii.gz',
        )

    bold_file = bold_files[0].path
    denoised_file = denoised_files[0].path

    if input_type == 'cifti':
        if (
            nb.load(bold_file)._nifti_header.get_intent()
            != nb.load(denoised_file)._nifti_header.get_intent()
        ):
            raise AssertionError(f'Intents do not match:\n\t{bold_file}\n\t{denoised_file}')

    elif not np.array_equal(nb.load(bold_file).affine, nb.load(denoised_file).affine):
        raise AssertionError(f'Affines do not match:\n\t{bold_file}\n\t{denoised_file}')

    print('No affines changed.')


@contextmanager
def chdir(path):
    """Temporarily change directories.

    Taken from https://stackoverflow.com/a/37996581/2589328.
    """
    oldpwd = os.getcwd()
    os.chdir(path)
    try:
        yield
    finally:
        os.chdir(oldpwd)


def reorder_expected_outputs():
    """Load each of the expected output files and sort the lines alphabetically.

    This function is called manually by devs when they modify the test outputs.
    """
    test_data_path = get_test_data_path()
    expected_output_files = sorted(glob(os.path.join(test_data_path, 'expected_outputs_*.txt')))
    for expected_output_file in expected_output_files:
        LOGGER.info(f'Sorting {expected_output_file}')

        with open(expected_output_file) as fobj:
            file_contents = fobj.readlines()

        file_contents = sorted(set(file_contents))

        with open(expected_output_file, 'w') as fobj:
            fobj.writelines(file_contents)


def _check_arg_specified(argname, arglist):
    for arg in arglist:
        if arg.startswith(argname):
            return True
    return False


def get_cpu_count(max_cpus=4):
    """Figure out how many cpus are available in the test environment."""
    env_cpus = os.getenv('CIRCLE_CPUS')
    if env_cpus:
        return int(env_cpus)
    return max_cpus


def update_resources(parameters):
    """We should use all the available CPUs for testing.

    Sometimes a test will set a specific amount of cpus. In that
    case, the number should be kept. Otherwise, try to read the
    env variable (specified in each job in config.yml). If
    this variable doesn't work, just set it to 4.
    """
    nthreads = get_cpu_count()
    if not _check_arg_specified('--nthreads', parameters):
        parameters.append(f'--nthreads={nthreads}')
    if not _check_arg_specified('--omp-nthreads', parameters):
        parameters.append(f'--omp-nthreads={nthreads}')
    return parameters
